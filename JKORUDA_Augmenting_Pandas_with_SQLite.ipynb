{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ZK7M8-wZ_J8"
      },
      "source": [
        "# Project Notebook: Augmenting Pandas with SQLite"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qadTA4HuceEl"
      },
      "source": [
        "## Question 1: Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aF9k8rixclSR"
      },
      "source": [
        "In this session, we explored a few different ways to work with larger datasets in pandas. In this guided project, we'll practice using some of the techniques we learned to analyze startup investments from Crunchbase.com.\n",
        "\n",
        "Every year, thousands of startup companies raise financing from investors. Each time a startup raises money, we refer to the event as a fundraising round. Crunchbase is a website that crowdsources information on the fundraising rounds of many startups. The Crunchbase user community submits, edits, and maintains most of the information in Crunchbase.\n",
        "\n",
        "In return, Crunchbase makes the data available through a Web application and a fee-based API. Before Crunchbase switched to the paid API model, multiple groups crawled the site and released the data online. Because the information on the startups and their fundraising rounds is always changing, the data set we'll be using isn't completely up to date.\n",
        "\n",
        "Throughout this project, we'll practice working with different memory constraints. In this step, let's assume we only have 10 megabytes of available memory. While crunchbase-investments.csv (https://bit.ly/3BPcobU) consumes 10.3 megabytes of disk space, we know from earlier lessons that pandas often requires 4 to 6 times amount of space in memory as the file does on disk (especially when there's many string columns).\n",
        "\n",
        "\n",
        "**Tasks**\n",
        "\n",
        "* Because the data set contains over 50,000 rows, you'll need to read the data set into dataframes using 5,000 row chunks to ensure that each chunk consumes much less than 10 megabytes of memory.\n",
        "* Across all of the chunks, become familiar with:\n",
        "1. Each column's missing value counts.\n",
        "2. Each column's memory footprint.\n",
        "3. The total memory footprint of all of the chunks combined.\n",
        "4. Which column(s) we can drop because they aren't useful for analysis.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tOYoNl5qe1ow",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbb68afa-4188-478f-ae84-81a856574e5d"
      },
      "source": [
        "# Your code goes here\n",
        "import pandas as pd\n",
        "# Dataset URL = https://bit.ly/3BPcobU\n",
        "# Downloading the data\n",
        "!wget -O crunchbase-investments.csv https://bit.ly/3BPcobU"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-05-08 05:42:27--  https://bit.ly/3BPcobU\n",
            "Resolving bit.ly (bit.ly)... 67.199.248.10, 67.199.248.11\n",
            "Connecting to bit.ly (bit.ly)|67.199.248.10|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://archive.org/download/crunchbase-investments/crunchbase-investments.csv [following]\n",
            "--2023-05-08 05:42:27--  https://archive.org/download/crunchbase-investments/crunchbase-investments.csv\n",
            "Resolving archive.org (archive.org)... 207.241.224.2\n",
            "Connecting to archive.org (archive.org)|207.241.224.2|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://ia904601.us.archive.org/28/items/crunchbase-investments/crunchbase-investments.csv [following]\n",
            "--2023-05-08 05:42:28--  https://ia904601.us.archive.org/28/items/crunchbase-investments/crunchbase-investments.csv\n",
            "Resolving ia904601.us.archive.org (ia904601.us.archive.org)... 207.241.235.61\n",
            "Connecting to ia904601.us.archive.org (ia904601.us.archive.org)|207.241.235.61|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10339663 (9.9M) [text/csv]\n",
            "Saving to: ‘crunchbase-investments.csv’\n",
            "\n",
            "crunchbase-investme 100%[===================>]   9.86M  15.0MB/s    in 0.7s    \n",
            "\n",
            "2023-05-08 05:42:29 (15.0 MB/s) - ‘crunchbase-investments.csv’ saved [10339663/10339663]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Introductory tasks**\n",
        "\n",
        "Read the data set into dataframes using 5,000 row chunks to ensure that each chunk consumes much less than 10 megabytes of memory"
      ],
      "metadata": {
        "id": "h0cji76JOxLd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an iterable for iterating over the chunks\n",
        "df_crunch_iter = pd.read_csv('crunchbase-investments.csv', chunksize=5000, encoding_errors='ignore')"
      ],
      "metadata": {
        "id": "2AW7JovIPCan"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the memory usage of the first chunk\n",
        "df_crunch = next(df_crunch_iter)\n",
        "\n",
        "print(df_crunch.info(memory_usage='deep'))\n",
        "# The printout below shows a memory usage for the chunck of 5.6 MB.\n",
        "\n",
        "# It also shows how much memory each column utilizes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "env4zrjOPJES",
        "outputId": "1c16275d-dbfa-4806-9ab9-430024870f69"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 5000 entries, 0 to 4999\n",
            "Data columns (total 20 columns):\n",
            " #   Column                  Non-Null Count  Dtype  \n",
            "---  ------                  --------------  -----  \n",
            " 0   company_permalink       5000 non-null   object \n",
            " 1   company_name            5000 non-null   object \n",
            " 2   company_category_code   4948 non-null   object \n",
            " 3   company_country_code    5000 non-null   object \n",
            " 4   company_state_code      4947 non-null   object \n",
            " 5   company_region          5000 non-null   object \n",
            " 6   company_city            4936 non-null   object \n",
            " 7   investor_permalink      5000 non-null   object \n",
            " 8   investor_name           5000 non-null   object \n",
            " 9   investor_category_code  2443 non-null   object \n",
            " 10  investor_country_code   4222 non-null   object \n",
            " 11  investor_state_code     3629 non-null   object \n",
            " 12  investor_region         5000 non-null   object \n",
            " 13  investor_city           4100 non-null   object \n",
            " 14  funding_round_type      5000 non-null   object \n",
            " 15  funded_at               5000 non-null   object \n",
            " 16  funded_month            5000 non-null   object \n",
            " 17  funded_quarter          5000 non-null   object \n",
            " 18  funded_year             5000 non-null   int64  \n",
            " 19  raised_amount_usd       4347 non-null   float64\n",
            "dtypes: float64(1), int64(1), object(18)\n",
            "memory usage: 5.6 MB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check columns in the chunk with missing values\n",
        "\n",
        "# df_crunch_numeric = df_loans.select_dtypes(include=['float16', 'float32', 'float64'])\n",
        "for col in df_crunch:\n",
        "    num_missing_vals = df_crunch[col].isnull().sum()\n",
        "    print(col,  '=> Missing values: ', num_missing_vals)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ARMyOwnqPkpg",
        "outputId": "b17a185a-4227-4a4b-ffd9-4c705f3d324c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "company_permalink => Missing values:  0\n",
            "company_name => Missing values:  0\n",
            "company_category_code => Missing values:  52\n",
            "company_country_code => Missing values:  0\n",
            "company_state_code => Missing values:  53\n",
            "company_region => Missing values:  0\n",
            "company_city => Missing values:  64\n",
            "investor_permalink => Missing values:  0\n",
            "investor_name => Missing values:  0\n",
            "investor_category_code => Missing values:  2557\n",
            "investor_country_code => Missing values:  778\n",
            "investor_state_code => Missing values:  1371\n",
            "investor_region => Missing values:  0\n",
            "investor_city => Missing values:  900\n",
            "funding_round_type => Missing values:  0\n",
            "funded_at => Missing values:  0\n",
            "funded_month => Missing values:  0\n",
            "funded_quarter => Missing values:  0\n",
            "funded_year => Missing values:  0\n",
            "raised_amount_usd => Missing values:  653\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Memory usage of columns\n",
        "df_crunch = pd.read_csv('crunchbase-investments.csv', encoding_errors='ignore')\n",
        "print(df_crunch.memory_usage(deep='True'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-1ItIDzPual",
        "outputId": "6dcef91a-1faa-494e-fd23-8080e879df5c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-dcf6a03b8d6c>:2: DtypeWarning: Columns (9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df_crunch = pd.read_csv('crunchbase-investments.csv', encoding_errors='ignore')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index                         128\n",
            "company_permalink         4057788\n",
            "company_name              3590018\n",
            "company_category_code     3421104\n",
            "company_country_code      3172176\n",
            "company_state_code        3106051\n",
            "company_region            3411545\n",
            "company_city              3505886\n",
            "investor_permalink        4980548\n",
            "investor_name             3914250\n",
            "investor_category_code    1771304\n",
            "investor_country_code     2836172\n",
            "investor_state_code       2665487\n",
            "investor_region           3395797\n",
            "investor_city             3071603\n",
            "funding_round_type        3410707\n",
            "funded_at                 3542185\n",
            "funded_month              3383584\n",
            "funded_quarter            3383584\n",
            "funded_year                422960\n",
            "raised_amount_usd          422960\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Memory usage across all the chunks\n",
        "\n",
        "# Reset the iterable\n",
        "df_crunch_iter = pd.read_csv('crunchbase-investments.csv', chunksize=5000, encoding_errors='ignore')\n",
        "\n",
        "memory_used = 0\n",
        "\n",
        "# Iterate over all the chunks\n",
        "for df_loans in df_crunch_iter:\n",
        "    memory_used += df_loans.memory_usage(deep=True).sum()\n",
        "\n",
        "print('Total memory across chunks: ', memory_used)\n",
        "\n",
        "# From the output below, memory across chunks is 59.7 MB"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W2J2VZ5FP4Gv",
        "outputId": "b551e14a-15a9-4bc5-97b4-500d5843ad0f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total memory across chunks:  59751637\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Columns which may not be useful for analysis:**\n",
        "\n",
        "The columns with many missing values will probably not be useful for analysis. These include: \n",
        "- company_category_code\n",
        "- company_state_code\n",
        "- investor_category_code\n",
        "- investor_country_code\n",
        "- investor_state_code\n",
        "- investor_city\n",
        "- raised_amount_usd"
      ],
      "metadata": {
        "id": "E1o9ffzxQHKC"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NOEk3_YPdg6p"
      },
      "source": [
        "## Question 2: Selecting Data Types"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FD1IqmzhcEd3"
      },
      "source": [
        "Now that we have a good sense of the missing values, let's get familiar with the column types before adding the data into SQLite.\n",
        "\n",
        "**Tasks**\n",
        "\n",
        "* Identify the types for each column.\n",
        "* Identify the numeric columns we can represent using more space efficient types.\n",
        "For text columns:\n",
        "* Analyze the unique value counts across all of the chunks to see if we can convert them to a numeric type.\n",
        "* See if we clean clean any text columns and separate them into multiple numeric columns without adding any overhead when querying.\n",
        "* Make your changes to the code from the last step so that the overall memory the data consumes stays under 10 megabytes.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Identify data types for each column\n",
        "\n",
        "The types for each column can be seen from the output of the memory usage function above: the columns with type 'object' are strings (column 0 - 17). Column 18 and 19 are int and float, respectively, as the output shows.\n",
        "\n",
        "The column types can also be gleaned from inspecting the actual csv file."
      ],
      "metadata": {
        "id": "6rfDkHUPQggl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Numeric columns we can represent using more space efficient types\n",
        "\n",
        "Column 18 is a float64 and can be converted to an integer."
      ],
      "metadata": {
        "id": "PruPPbscQt4v"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNgzuiStZ3WN"
      },
      "source": [
        "# Function to convert floats to integer\n",
        "from pandas.api.types import is_numeric_dtype\n",
        "\n",
        "def to_integers(df):\n",
        "    for col in df:\n",
        "        if is_numeric_dtype(df[col]):\n",
        "            if df[col].isnull().sum() == 0:\n",
        "                df[col] = df[col].astype('int')\n",
        "                df[col] = pd.to_numeric(df[col], downcast='integer')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reset the iterable\n",
        "df_crunch_iter = pd.read_csv('crunchbase-investments.csv', chunksize=5000, encoding_errors='ignore')\n",
        "df_crunch = next(df_crunch_iter)\n",
        "\n",
        "print('Before conversion: ', df_crunch.memory_usage(deep=True).sum())\n",
        "to_integers(df_crunch)\n",
        "print('After conversion: ', df_crunch.memory_usage(deep=True).sum())\n",
        "\n",
        "# As the ouput below shows, changing col 18 from float to int achieves a slightly lower memory usage"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y9u5tmFlQ94C",
        "outputId": "9bce600c-e4ec-4edb-b818-b1755350582f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before conversion:  5849432\n",
            "After conversion:  5819432\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Analyze unique value counts across all chunks"
      ],
      "metadata": {
        "id": "u4A1frd8RNL8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of unique values in each string column\n",
        "\n",
        "# Reset the iterable\n",
        "df_crunch_iter = pd.read_csv('crunchbase-investments.csv', chunksize=5000, encoding_errors='ignore')\n",
        "\n",
        "# Dictionary to keep track of value counts\n",
        "crunch_val_count = {}\n",
        "num_rows = 0\n",
        "\n",
        "def count_unique(df):\n",
        "    for col in df:\n",
        "        num_unique = len(df[col].value_counts())\n",
        "        if col not in crunch_val_count.keys():\n",
        "            crunch_val_count[col] = num_unique\n",
        "        else:\n",
        "            crunch_val_count[col] += num_unique\n",
        "\n",
        "# Count the unique values for all chunks\n",
        "for df_crunch in df_crunch_iter:\n",
        "    num_rows += len(df_crunch)\n",
        "\n",
        "    df_crunch_string = df_crunch.select_dtypes(include=['object'])\n",
        "    count_unique(df_crunch_string)\n",
        "\n",
        "\n",
        "# count_unique(df_crunch_string)\n",
        "print('Number of unique values for each column:\\n')\n",
        "for field, count in crunch_val_count.items():\n",
        "    print(f'{field}: {count} (Ratio: {count / num_rows * 100:.2f}%)')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s9zrRcPCRRFj",
        "outputId": "79e44ca2-d572-4849-eed0-2d10293e60b1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of unique values for each column:\n",
            "\n",
            "company_permalink: 30586 (Ratio: 57.85%)\n",
            "company_name: 30586 (Ratio: 57.85%)\n",
            "company_category_code: 451 (Ratio: 0.85%)\n",
            "company_country_code: 12 (Ratio: 0.02%)\n",
            "company_state_code: 494 (Ratio: 0.93%)\n",
            "company_region: 2066 (Ratio: 3.91%)\n",
            "company_city: 5181 (Ratio: 9.80%)\n",
            "investor_permalink: 10558 (Ratio: 19.97%)\n",
            "investor_name: 10485 (Ratio: 19.83%)\n",
            "investor_category_code: 33 (Ratio: 0.06%)\n",
            "investor_country_code: 310 (Ratio: 0.59%)\n",
            "investor_state_code: 327 (Ratio: 0.62%)\n",
            "investor_region: 1337 (Ratio: 2.53%)\n",
            "investor_city: 2038 (Ratio: 3.85%)\n",
            "funding_round_type: 88 (Ratio: 0.17%)\n",
            "funded_at: 18304 (Ratio: 34.62%)\n",
            "funded_month: 1676 (Ratio: 3.17%)\n",
            "funded_quarter: 656 (Ratio: 1.24%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "By inspecting the output from the cell above, we see that ALL the string columns except `company_permalink` and `company_name` have less than 50% unique values. The columns with less than 50% unique values can be optimized by converting to categorical types."
      ],
      "metadata": {
        "id": "Ie_MSfFERk3K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reset the iterable\n",
        "df_crunch_iter = pd.read_csv('crunchbase-investments.csv', chunksize=5000, encoding_errors='ignore')\n",
        "df_crunch = next(df_crunch_iter)\n",
        "# df_crunch_string = df_crunch.select_dtypes(include=['object'])\n",
        "\n",
        "def to_categorical(df):\n",
        "    # num_rows is the number of rows in the chunk\n",
        "    num_rows = df.shape[0]\n",
        "\n",
        "    for col in df:\n",
        "        if len(df[col].value_counts()) / num_rows < 0.5 and not is_numeric_dtype(df[col]):\n",
        "            df[col] = df[col].astype('category')\n",
        "\n",
        "# Testing to ascertain memory reduction\n",
        "print('Before optimization: ', df_crunch.memory_usage(deep=True).sum())\n",
        "to_categorical(df_crunch)\n",
        "print('After optimization: ', df_crunch.memory_usage(deep=True).sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DXQ9BQiZRmQD",
        "outputId": "07204a6a-b2a5-485a-f85d-48619ecb80cf"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before optimization:  5849432\n",
            "After optimization:  1579992\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The output from the cell above shows a significant reduction in memory for a single chunk."
      ],
      "metadata": {
        "id": "qhcghQBBR7Wq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clean some text columns and separate them into multiple numeric columns "
      ],
      "metadata": {
        "id": "dlGA5nTkSE6D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The funded_at column can be split into 3 columns, so that all of them are integers. After that, funded_month and funded_year are not useful since their information is contained in funded_at."
      ],
      "metadata": {
        "id": "AnrLOezkSOAx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reset the iterable\n",
        "df_crunch_iter = pd.read_csv('crunchbase-investments.csv', chunksize=5000, encoding_errors='ignore')\n",
        "df_crunch = next(df_crunch_iter)\n",
        "\n",
        "# Check size before operations\n",
        "print('Before: ', df_crunch.memory_usage(deep=True).sum())\n",
        "\n",
        "def clean_text_cols(df):\n",
        "    #drop some unnecessary columns\n",
        "    df.drop(['funded_month', 'funded_year'], axis=1, inplace=True)\n",
        "\n",
        "    # Split the appropriate column\n",
        "    df[['funded_year', 'funded_month', 'funded_day']] = df['funded_at'].str.split('-', expand=True)\n",
        "    # Then drop the columns not necessary\n",
        "    df.drop(['funded_at'], axis=1, inplace=True)\n",
        "\n",
        "    # After the above, those three columns can be converted to integers\n",
        "\n",
        "    for col in ['funded_year', 'funded_month', 'funded_day']:\n",
        "        if df[col].isnull().sum() == 0:\n",
        "            df[col] = df[col].astype('int')\n",
        "            df[col] = pd.to_numeric(df_crunch[col], downcast='integer')\n",
        "\n",
        "clean_text_cols(df_crunch)\n",
        "\n",
        "print('After: ', df_crunch.memory_usage(deep=True).sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "adDDodxqSa53",
        "outputId": "f48e9a95-c71d-4014-fc8f-ff1e64beab06"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before:  5849432\n",
            "After:  5174432\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OA2D7o4sds1t"
      },
      "source": [
        "## Question 3: Loading Chunks Into SQLite"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptu8Xr25dvcF"
      },
      "source": [
        "Now we're in good shape to start exploring and analyzing the data. The next step is to load each chunk into a table in a SQLite database so we can query the full data set.\n",
        "\n",
        "**Tasks**\n",
        "\n",
        "1. Create and connect to a new SQLite database file.\n",
        "2. Expand on the existing chunk processing code to export each chunk to a new table in the SQLite database.\n",
        "3. Query the table and make sure the data types match up to what you had in mind for each column."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QH-j6fuXdu0v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4f3af05-7e43-4d0a-cd63-f91de44150ce"
      },
      "source": [
        "# First bring together everything done in the cells above into one place\n",
        "\n",
        "def preprocess_chunk(df):\n",
        "    # Numeric columns wiht more efficient representation\n",
        "    to_integers(df)\n",
        "\n",
        "    # Optimize string columns\n",
        "    to_categorical(df)\n",
        "\n",
        "    # Clean text columns\n",
        "    clean_text_cols(df)\n",
        "\n",
        "# Reset the iterable\n",
        "df_crunch_iter = pd.read_csv('crunchbase-investments.csv', chunksize=5000, encoding_errors='ignore')\n",
        "df_crunch = next(df_crunch_iter)\n",
        "\n",
        "# Check size before and after preprocessing\n",
        "print('Before: ', df_crunch.memory_usage(deep=True).sum())\n",
        "preprocess_chunk(df_crunch)\n",
        "print('After: ', df_crunch.memory_usage(deep=True).sum())"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before:  5849432\n",
            "After:  1347201\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create and connect to a new SQLite database file."
      ],
      "metadata": {
        "id": "jxDTM-_3S8Eg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create and connect to a new SQLite database file\n",
        "import sqlite3\n",
        "conn = sqlite3.connect('crunchbase.db')"
      ],
      "metadata": {
        "id": "bZbrixmtTCSp"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Export each chunk to a new table in the SQLite database."
      ],
      "metadata": {
        "id": "FSbCbj40TL53"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reset the iterable\n",
        "df_crunch_iter = pd.read_csv('crunchbase-investments.csv', chunksize=5000, encoding_errors='ignore')\n",
        "\n",
        "for df_crunch in df_crunch_iter:\n",
        "    preprocess_chunk(df_crunch)\n",
        "    df_crunch.to_sql('crunchbase', conn, if_exists='append', index=False)"
      ],
      "metadata": {
        "id": "GrsandmbTOSn"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a cursor object to query the sqlite db\n",
        "cursor = conn.cursor()\n",
        "\n",
        "# Check that the crunchbase table actually exists in the db\n",
        "sql_query = \"\"\"SELECT name FROM sqlite_master WHERE type='table';\"\"\"\n",
        "result = cursor.execute(sql_query)\n",
        "print(result.fetchall())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uhrvnxf5VQug",
        "outputId": "1be7a593-c1cb-4b9f-8119-5af03c69bf0f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('crunchbase',)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Query the table "
      ],
      "metadata": {
        "id": "OGSfO65CVkog"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Query to check the data types of the columns in the sqlite db\n",
        "sql_query = \"\"\"PRAGMA table_info(crunchbase);\"\"\"\n",
        "results = cursor.execute(sql_query).fetchall()\n",
        "# Print the result\n",
        "for result in results:\n",
        "    print(f'{result[1]} => {result[2]}')\n",
        "# The indices for result above were determined by first printing out to see \n",
        "# the index of the column name and data type"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7dbrT2xVqv4",
        "outputId": "9052f191-91c1-40da-92b9-0719d410391e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "company_permalink => TEXT\n",
            "company_name => TEXT\n",
            "company_category_code => TEXT\n",
            "company_country_code => TEXT\n",
            "company_state_code => TEXT\n",
            "company_region => TEXT\n",
            "company_city => TEXT\n",
            "investor_permalink => TEXT\n",
            "investor_name => TEXT\n",
            "investor_category_code => TEXT\n",
            "investor_country_code => TEXT\n",
            "investor_state_code => TEXT\n",
            "investor_region => TEXT\n",
            "investor_city => TEXT\n",
            "funding_round_type => TEXT\n",
            "funded_quarter => TEXT\n",
            "raised_amount_usd => REAL\n",
            "funded_year => INTEGER\n",
            "funded_month => INTEGER\n",
            "funded_day => INTEGER\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The output from the cell shows that the query of the database using sql reveals that the datatypes are as expected following the prior optimizations that were done using pandas. For example, funded_year, funded_month and funded_day are integers, rather than having funded_at as a string."
      ],
      "metadata": {
        "id": "Me9v_LB3WCXH"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rt1jPEhseD8r"
      },
      "source": [
        "## Question 4: Next Steps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ggt-hEebeJGr"
      },
      "source": [
        "Now that the data is in SQLite, we can use the pandas SQLite workflow we learned in the last lesson to explore and analyze startup investments. Remember that each row isn't a unique company, but a unique investment from a single investor. This means that many startups will span multiple rows.\n",
        "\n",
        "Use the pandas SQLite workflow to answer the following questions:\n",
        "\n",
        "* What proportion of the total amount of funds did the top 10% raise? What about the top 1%? Compare these values to the proportions the bottom 10% and bottom 1% raised.\n",
        "* Which category of company attracted the most investments?\n",
        "* Which investor contributed the most money (across all startups)?\n",
        "* Which investors contributed the most money per startup?\n",
        "* Which funding round was the most popular? Which was the least popular?\n",
        "\n",
        "Here are some ideas for further exploration:\n",
        "\n",
        "* Repeat the tasks in this project using stricter memory constraints (under 1 megabyte).\n",
        "* Clean and analyze the other Crunchbase data sets from the same GitHub repo.\n",
        "* Understand which columns the data sets share, and how the data sets are linked.\n",
        "* Create a relational database design that links the data sets together and reduces the overall disk space the database file consumes.\n",
        "\n",
        "Use pandas to populate each table in the database, create the appropriate indexes, and so on."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What proportion of the total amount of funds did the top/bottom 10% and 1% raise?"
      ],
      "metadata": {
        "id": "h42q4DH04LTx"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJo2f7N-ebgX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0bec00c9-b57b-44e2-9fd6-c6a0f537e7c8"
      },
      "source": [
        "# First find the total amount of funds raised\n",
        "query = \"SELECT SUM(raised_amount_usd) AS total_amount_raised FROM crunchbase\"\n",
        "total_amount_raised = pd.read_sql(query, conn)\n",
        "print(total_amount_raised, '\\n')\n",
        "\n",
        "# Amount raised by the various startups%\n",
        "query = \"\"\"SELECT company_name, investor_name, SUM(raised_amount_usd) AS raised_amount \n",
        "            FROM crunchbase GROUP BY investor_name\n",
        "            HAVING raised_amount > 0\n",
        "            ORDER BY raised_amount DESC\"\"\"\n",
        "# The 'HAVING raised_amount > 0' has been introduced to eliminate the startups which have a blank\n",
        "# for raised amount for any one of their investors.\n",
        "startup_amounts = pd.read_sql(query, conn)\n",
        "print(startup_amounts)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   total_amount_raised\n",
            "0         6.817322e+11 \n",
            "\n",
            "            company_name                                      investor_name  \\\n",
            "0               LifeLock                   Kleiner Perkins Caufield & Byers   \n",
            "1         ChannelAdvisor                          New Enterprise Associates   \n",
            "2               Facebook                                     Accel Partners   \n",
            "3                   Veoh                                      Goldman Sachs   \n",
            "4                  Joost                                    Sequoia Capital   \n",
            "...                  ...                                                ...   \n",
            "9810  PictureMe Universe  UW-Eau Claire Entrepreneur Program CEO Idea Ch...   \n",
            "9811        TrustDegrees                                     Sean Barberous   \n",
            "9812            uromovie                                                cnc   \n",
            "9813  PictureMe Universe  UW-Eau Claire Office of Research and Sponsored...   \n",
            "9814   Main Street Stark                                    Jeff SKI Kinsey   \n",
            "\n",
            "      raised_amount  \n",
            "0      1.121783e+10  \n",
            "1      9.692542e+09  \n",
            "2      6.472126e+09  \n",
            "3      6.375459e+09  \n",
            "4      6.039402e+09  \n",
            "...             ...  \n",
            "9810   3.000000e+03  \n",
            "9811   3.000000e+03  \n",
            "9812   2.000000e+03  \n",
            "9813   1.000000e+03  \n",
            "9814   1.000000e+03  \n",
            "\n",
            "[9815 rows x 3 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the output of the cell above, we have the total amount raised and the amount raised by each startup. We also see that there are 9815 startups which are listed (NB: these are the ones that have complete data). We can therefore get the amount of funds raised by the top 10% (top 982 rows) and top 1% (top 98 rows) by simple division, as follows."
      ],
      "metadata": {
        "id": "EFIskyfT5-xZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Proportion of funds raised by top 10%\n",
        "proportion = 100 * sum(startup_amounts['raised_amount'][:982]) / total_amount_raised['total_amount_raised'][0]\n",
        "print(f'Proportion raised by top 10%: {proportion:.2f}%')\n",
        "\n",
        "# Proportion of funds raised by top 1%\n",
        "proportion = 100 * sum(startup_amounts['raised_amount'][:98]) / total_amount_raised['total_amount_raised'][0]\n",
        "print(f'Proportion raised by top 1%: {proportion:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uKt3wIYM6LCX",
        "outputId": "5747dcd0-8695-4779-d3b5-fe11bb23e748"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Proportion raised by top 10%: 81.91%\n",
            "Proportion raised by top 1%: 39.40%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Proportion of funds raised by bottom 10%\n",
        "proportion = 100 * sum(startup_amounts['raised_amount'][-982:]) / total_amount_raised['total_amount_raised'][0]\n",
        "print(f'Proportion raised by bottom 10%: {proportion:.2f}%')\n",
        "\n",
        "# Proportion of funds raised by bottom 1%\n",
        "proportion = 100 * sum(startup_amounts['raised_amount'][-98:]) / total_amount_raised['total_amount_raised'][0]\n",
        "print(f'Proportion raised by bottom 1%: {proportion:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gz-DE7v46VSa",
        "outputId": "7e752364-ed1e-497e-a02a-525d559dd66c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Proportion raised by bottom 10%: 0.03%\n",
            "Proportion raised by bottom 1%: 0.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Which category of company attracted the most investments?"
      ],
      "metadata": {
        "id": "pqAowk8a6ap8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"\"\"\n",
        "            SELECT company_category_code, COUNT(*) AS num_investments\n",
        "            FROM crunchbase GROUP BY company_category_code \n",
        "            HAVING company_category_code != 'None' AND num_investments > 1\n",
        "            ORDER BY num_investments DESC\n",
        "            \"\"\"\n",
        "company_category_counts = pd.read_sql(query, conn)\n",
        "print(company_category_counts, '\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O98nONo76l0c",
        "outputId": "029f40e4-ac69-467a-c191-cb8c1c1c30d7"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   company_category_code  num_investments\n",
            "0               software             7243\n",
            "1                    web             5015\n",
            "2                biotech             4951\n",
            "3             enterprise             4489\n",
            "4                 mobile             4067\n",
            "5            advertising             3200\n",
            "6              ecommerce             2168\n",
            "7              cleantech             1948\n",
            "8            games_video             1893\n",
            "9              analytics             1863\n",
            "10              hardware             1537\n",
            "11               medical             1315\n",
            "12         semiconductor             1292\n",
            "13       network_hosting             1075\n",
            "14              security              996\n",
            "15               finance              931\n",
            "16                social              920\n",
            "17             education              783\n",
            "18                health              670\n",
            "19      public_relations              659\n",
            "20                search              632\n",
            "21                 other              481\n",
            "22             messaging              452\n",
            "23               fashion              368\n",
            "24                  news              363\n",
            "25                travel              337\n",
            "26           hospitality              331\n",
            "27         manufacturing              310\n",
            "28                 music              287\n",
            "29            consulting              233\n",
            "30           photo_video              230\n",
            "31              nanotech              216\n",
            "32           real_estate              190\n",
            "33            automotive              164\n",
            "34             nonprofit              149\n",
            "35        transportation              130\n",
            "36                sports              121\n",
            "37                 legal               87\n",
            "38                design               55\n",
            "39                  pets               43\n",
            "40                 local               22\n",
            "41            government               10 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the output of the cell above, it can be seen that **software** companies attracted the most investments."
      ],
      "metadata": {
        "id": "tx3s7lSk6q5B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Which investor contributed the most money (across all startups)?"
      ],
      "metadata": {
        "id": "7crrhpA56w8w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"\"\"\n",
        "            SELECT investor_name, company_name, MAX(raised_amount_usd) AS amount_invested\n",
        "            FROM crunchbase GROUP BY investor_name, company_name \n",
        "            ORDER BY amount_invested DESC\n",
        "            \"\"\"\n",
        "most_per_startup = pd.read_sql(query, conn)\n",
        "print(most_per_startup)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ri3yBkzS6-79",
        "outputId": "877c3b1d-1ceb-4b2c-bae4-df29b086bb11"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "             investor_name      company_name  amount_invested\n",
            "0              BrightHouse         Clearwire     3.200000e+09\n",
            "1                  Comcast         Clearwire     3.200000e+09\n",
            "2                   Google         Clearwire     3.200000e+09\n",
            "3                    Intel         Clearwire     3.200000e+09\n",
            "4              Time Warner         Clearwire     3.200000e+09\n",
            "...                    ...               ...              ...\n",
            "40963      reinmkr capital          GazeHawk              NaN\n",
            "40964      reinmkr capital          Voicendo              NaN\n",
            "40965      vSpring Capital  BioMicro Systems              NaN\n",
            "40966  ventureblue Capital            Mangia              NaN\n",
            "40967    venturecapital.de            zuuka!              NaN\n",
            "\n",
            "[40968 rows x 3 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the output of the cell above we see that BrightHouse contributed the most money for a single startup; they contributied $3,200,000,000 to Clearwire."
      ],
      "metadata": {
        "id": "g2swkwhc7EZf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(most_per_startup['amount_invested'][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jgGhL_wt7FJI",
        "outputId": "03235864-8d03-4934-faef-75cb4d048376"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3200000000.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Which funding round was the most popular? Which was the least popular?"
      ],
      "metadata": {
        "id": "g-VCUPhq7NsI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"\"\"\n",
        "            SELECT funding_round_type, COUNT(*) AS occurences\n",
        "            FROM crunchbase GROUP BY funding_round_type \n",
        "            HAVING funding_round_type != 'None'\n",
        "            ORDER BY occurences DESC\n",
        "            \"\"\"\n",
        "most_popular = pd.read_sql(query, conn)\n",
        "print(most_popular, '\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2T9Egk0u7VqQ",
        "outputId": "5218fec8-d05b-4653-cef7-c29593516057"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  funding_round_type  occurences\n",
            "0           series-a       13938\n",
            "1          series-c+       10870\n",
            "2              angel        8989\n",
            "3            venture        8917\n",
            "4           series-b        8794\n",
            "5              other         964\n",
            "6     private-equity         357\n",
            "7           post-ipo          33\n",
            "8       crowdfunding           5 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the output of the cell above, we see that the **series-a round was most popular** and the **crowdfunding was least popular**"
      ],
      "metadata": {
        "id": "l84_q0HY7aiC"
      }
    }
  ]
}